!pip install torch torchvision torchaudio


!pip install torch-geometric


!pip install torch torchvision torch-geometric scikit-image matplotlib seaborn


# Imports
import cv2
import numpy as np
import torch
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_max_pool
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.manifold import TSNE



# -------------------------------
# 1. Graph Construction (Grid-based)
# -------------------------------
def grid_graph(img):
    img = (img.squeeze().numpy() * 255).astype(np.uint8)
    h, w = img.shape
    nodes = np.stack(np.mgrid[0:h, 0:w], axis=-1).reshape(-1, 2)
    nodes = nodes / 27.0  # Normalize to [0,1]
    
    # Create 8-neighbor connections
    edge_index = []
    for i in range(h):
        for j in range(w):
            idx = i * w + j
            for di in [-1, 0, 1]:
                for dj in [-1, 0, 1]:
                    if di == 0 and dj == 0:
                        continue
                    ni, nj = i + di, j + dj
                    if 0 <= ni < h and 0 <= nj < w:
                        edge_index.append([idx, ni * w + nj])
    
    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    
    # Node features: (x, y, intensity)
    intensities = img.flatten() / 255.0
    x = torch.tensor(np.hstack([nodes, intensities.reshape(-1, 1)]), dtype=torch.float)
    
    return Data(x=x, edge_index=edge_index)


# -------------------------------
# 2. GNN Architectures
# -------------------------------
class GCN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(3, 64)
        self.conv2 = GCNConv(64, 128)
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(128, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 10))
        
    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = F.relu(self.conv1(x, edge_index))
        x = F.relu(self.conv2(x, edge_index))
        x = global_max_pool(x, data.batch)
        return F.log_softmax(self.fc(x), dim=1)

class GAT(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GATConv(3, 64, heads=4)
        self.conv2 = GATConv(64*4, 128, heads=2)
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(128*2, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 10))
        
    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = F.elu(self.conv1(x, edge_index))
        x = F.elu(self.conv2(x, edge_index))
        x = global_max_pool(x, data.batch)
        return F.log_softmax(self.fc(x), dim=1)

class GraphSAGE(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = SAGEConv(3, 64)
        self.conv2 = SAGEConv(64, 128)
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(128, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 10))
        
    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = F.relu(self.conv1(x, edge_index))
        x = F.relu(self.conv2(x, edge_index))
        x = global_max_pool(x, data.batch)
        return F.log_softmax(self.fc(x), dim=1)



# -------------------------------
# 3. Training/Evaluation Framework
# -------------------------------
class Trainer:
    def __init__(self, model, train_loader, test_loader):
        self.model = model
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.005)
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=20)
        
        self.train_losses = []
        self.test_accs = []
    
    def train_epoch(self):
        self.model.train()
        total_loss = 0
        for data in self.train_loader:
            self.optimizer.zero_grad()
            out = self.model(data)
            loss = F.nll_loss(out, data.y)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
            self.optimizer.step()
            total_loss += loss.item()
        self.scheduler.step()
        return total_loss / len(self.train_loader)
    
    def evaluate(self):
        self.model.eval()
        correct = 0
        for data in self.test_loader:
            out = self.model(data)
            pred = out.argmax(dim=1)
            correct += (pred == data.y).sum().item()
        return correct / len(self.test_loader.dataset)
    
    def run(self, epochs=30):
        best_acc = 0
        for epoch in range(epochs):
            loss = self.train_epoch()
            acc = self.evaluate()
            
            self.train_losses.append(loss)
            self.test_accs.append(acc)
            
            if acc > best_acc:
                best_acc = acc
                torch.save(self.model.state_dict(), 'best_model.pth')
            
            print(f'Epoch {epoch+1:02d}: Loss={loss:.4f} Acc={acc:.4f} LR={self.scheduler.get_last_lr()[0]:.6f}')
        return best_acc


# -------------------------------
# 4. Visualization Utilities
# -------------------------------
def plot_metrics(models_history):
    plt.figure(figsize=(12, 4))
    
    # Loss curves
    plt.subplot(1, 2, 1)
    for name, history in models_history.items():
        plt.plot(history['loss'], label=name)
    plt.xlabel('Epoch'), plt.ylabel('Loss')
    plt.legend()
    
    # Accuracy curves
    plt.subplot(1, 2, 2)
    for name, history in models_history.items():
        plt.plot(history['acc'], label=name)
    plt.xlabel('Epoch'), plt.ylabel('Accuracy')
    plt.legend()
    
    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(model, loader):
    model.eval()
    y_true, y_pred = [], []
    for data in loader:
        out = model(data)
        pred = out.argmax(dim=1)
        y_true.extend(data.y.tolist())
        y_pred.extend(pred.tolist())
    
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# def plot_embeddings(model, loader):
#     model.eval()
#     embeddings, labels = [], []
#     for data in loader:
#         out = model.conv2(model.conv1(data.x, data.edge_index))
#         embeddings.append(out.detach())
#         labels.append(data.y)
    
#     embeddings = torch.cat(embeddings).numpy()
#     labels = torch.cat(labels).numpy()
    
#     tsne = TSNE(n_components=2).fit_transform(embeddings)
#     plt.figure(figsize=(8, 6))
#     plt.scatter(tsne[:,0], tsne[:,1], c=labels, cmap='tab10', s=10)
#     plt.colorbar()
#     plt.show()




# -------------------------------
# 5. Main Execution
# -------------------------------
if __name__ == "__main__":
    # Dataset preparation
    train_dataset = MNIST('./data', train=True, download=True, transform=ToTensor())
    test_dataset = MNIST('./data', train=False, transform=ToTensor())

    # Create graphs (subset for demonstration)
    train_graphs = []
    for i in range(10000):  # Explicit indexing
        img, _ = train_dataset[i]
        train_graphs.append(grid_graph(img))
    
    test_graphs = []
    for i in range(2000):  # Explicit indexing
        img, _ = test_dataset[i]
        test_graphs.append(grid_graph(img))
    
    # Add labels
    for i in range(len(train_graphs)):
        train_graphs[i].y = torch.tensor(train_dataset[i][1], dtype=torch.long)
    for i in range(len(test_graphs)):
        test_graphs[i].y = torch.tensor(test_dataset[i][1], dtype=torch.long)

    train_loader = DataLoader(train_graphs, batch_size=128, shuffle=True)
    test_loader = DataLoader(test_graphs, batch_size=128)

    # Initialize models
    models = {
        'GCN': GCN(),
        'GAT': GAT(),
        'GraphSAGE': GraphSAGE()
    }

    # Train and evaluate
    results = {}
    for name, model in models.items():
        print(f"\n=== Training {name} ===")
        trainer = Trainer(model, train_loader, test_loader)
        best_acc = trainer.run(epochs=30)
        results[name] = {
            'acc': best_acc,
            'loss': trainer.train_losses,
            'acc_history': trainer.test_accs
        }
        plot_confusion_matrix(model, test_loader)
        # plot_embeddings(model, test_loader)

    # Compare all models
    plot_metrics({name: {'loss': res['loss'], 'acc': res['acc_history']} 
             for name, res in results.items()})

    
    print("\nFinal Results:")
    for name, res in results.items():
        print(f"{name}: Accuracy = {res['acc']:.4f}")






